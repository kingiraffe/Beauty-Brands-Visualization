{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from openpyxl import load_workbook\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions() # declare a Chrome Driver\n",
    "options.add_experimental_option('prefs', {'profile.managed_default_content_settings.images': 2}) # set not to display pictures\n",
    "browser = webdriver.Chrome(options= options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.jd.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startScraper(keywords):\n",
    "    data_list = [] # declare a list to store dicts\n",
    "    browser.get(url) # request url\n",
    "    browser.find_element_by_id('key').send_keys(keywords) # enter keywords\n",
    "    browser.find_element_by_id('key').send_keys(Keys.ENTER) # start search\n",
    "    WebDriverWait(browser, 1000).until(\n",
    "        EC.presence_of_all_elements_located(\n",
    "            (By.CLASS_NAME, 'pn-next')\n",
    "        )\n",
    "    ) # wait till all the elements all loaded\n",
    "    all_page = eval(browser.find_element_by_css_selector('span.p-skip em b').text) # get #num of pages\n",
    "    count = 0 # set a counter\n",
    "    # loop before the last page\n",
    "    while True:\n",
    "        try:\n",
    "            count += 1\n",
    "            # wait till all the information loaded\n",
    "            WebDriverWait(browser, 1000).until(\n",
    "                EC.presence_of_all_elements_located(\n",
    "                    (By.CLASS_NAME, 'gl-item')\n",
    "                )\n",
    "            )\n",
    "            browser.execute_script('document.documentElement.scrollTop=10000') # draw the bar to the bottom to load all the information\n",
    "            time.sleep(random.randint(1, 3)) # randomly stop for seconds\n",
    "            browser.execute_script('document.documentElement.scrollTop=0') # back to the top\n",
    "            \n",
    "            # extract information from label li\n",
    "            lis = browser.find_elements_by_class_name('gl-item')\n",
    "            for li in lis:\n",
    "                # name\n",
    "                name = li.find_element_by_xpath('.//div[@class=\"p-name p-name-type-2\"]//em').text\n",
    "                # price\n",
    "                price = li.find_element_by_xpath('.//div[@class=\"p-price\"]//i').text\n",
    "                # #num of comments\n",
    "                comment = li.find_elements_by_xpath('.//div[@class=\"p-commit\"]//a')\n",
    "                if comment:\n",
    "                    comment = comment[0].text\n",
    "                else:\n",
    "                    comment = None\n",
    "                # shop name\n",
    "                shop_name = li.find_elements_by_class_name('J_im_icon')\n",
    "                if shop_name:\n",
    "                    shop_name = shop_name[0].text\n",
    "                else:\n",
    "                    shop_name = None\n",
    "                # shop type\n",
    "                shop_type = li.find_elements_by_class_name('goods-icons')\n",
    "                if shop_type:\n",
    "                    shop_type = shop_type[0].text\n",
    "                else:\n",
    "                    shop_type = None\n",
    "                    \n",
    "                # declare a dict to store data\n",
    "                data_dict = {}\n",
    "                data_dict['name'] = name\n",
    "                data_dict['price'] = price\n",
    "                data_dict['comment'] = comment\n",
    "                data_dict['shop_name'] = shop_name\n",
    "                data_dict['shop_type'] = shop_type\n",
    "                \n",
    "                data_list.append(data_dict)\n",
    "                #print(data_dict)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "        if count == all_page:\n",
    "            break\n",
    "        # find element for next page and click\n",
    "        fp_next = browser.find_element_by_css_selector('a.fp-next')\n",
    "        browser.execute_script('document.documentElement.scrollTop = 10000')\n",
    "        fp_next.click()\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prune the 'comments' to 'sales'\n",
    "def prune_sales(comments):\n",
    "    if comments == None:\n",
    "        return int(0)\n",
    "    elif comments == '':\n",
    "        return int(0)\n",
    "    elif comments[-1] != '+':\n",
    "        return int(comments)\n",
    "    elif comments[-2] == '万':\n",
    "        return int(float(comments[:-2]) * 1e4)\n",
    "    else:\n",
    "        return int(comments[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data in excel\n",
    "def main(keywords):\n",
    "    result = startScraper(keywords)\n",
    "    result_df = pd.DataFrame(result)\n",
    "    result_df['sales'] = result_df['comment'].apply(prune_sales)\n",
    "    with pd.ExcelWriter('sku_sells.xlsx', engine = 'openpyxl') as writer:\n",
    "        writer.book = load_workbook('sku_sells.xlsx')\n",
    "        result_df.to_excel(writer, sheet_name = keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = \"雅诗兰黛\" # enter keywords\n",
    "main(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
